

<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>iGCT</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Beyond and Free from Diffusion: <br> <b>I</b>nvertible <b>G</b>uided <b>C</b>onsistency <b>T</b>raining <b>(iGCT)</b>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://swimmincatt35.github.io">
                          Chia-Hong Hsu
                        </a>
                        </br>Brown University
                    </li>
                   
                    <li>
                        <a href="https://cse.hkust.edu.hk/~skao/">
                            Shiu-Hong Kao
                        </a>
                        </br>HKUST
                    </li>
                    <li>
                        <a href="https://randallbalestriero.github.io/">
                            Randall Balestriero
                        </a>
                        </br>Brown University
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="">  <!-- Arxiv link here -->
                            <image src="img/paper.png" height="30px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/swimmincatt35/iGCT">
                            <image src="img/github.png" height="30px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>
        
        <!-- Video thumbnail -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2" style="text-align: center;">
                <video autoplay muted loop playsinline width="80%">
                       <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
                      <source src="img/demo.mp4#t=0.001" type="video/mp4">
                </video>
            </div>
        </div>
        
        <!-- Abstract -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3 style="text-align: center;margin-top: 30px;margin-bottom: 30px;">
                    Abstract
                </h3>
                <p class="text-justify">
                    Guidance in image generation steers models towards higher-quality or more targeted outputs, typically achieved in Diffusion Models (DMs) via Classifier-free Guidance (CFG). However, recent Consistency Models (CMs), which offer fewer function evaluations, rely on distilling CFG knowledge from pretrained DMs to achieve guidance, making them costly and inflexible. In this work, we propose invertible Guided Consistency Training (iGCT), a novel training framework for guided CMs that is entirely data-driven. iGCT, as a pioneering work, contributes to fast and guided image generation and editing without requiring the training and distillation of DMs, greatly reducing the overall compute requirements. iGCT addresses the saturation artifacts seen in CFG under high guidance scales. Our extensive experiments on CIFAR-10 and ImageNet64 show that iGCT significantly improves FID and precision compared to CFG. At a guidance of 13, iGCT improves precision to 0.8, while DM's drops to 0.47. Our work takes the first step toward enabling guidance and inversion for CMs without relying on DMs.                
                </p>
                <p class="text-justify">
                    <strong>Video: </strong> Real-time image editing with iGCT, 1-step inversion (via noiser) and editing (via denoiser).
                </p>
            </div>
        </div>
        
        <!-- Alg Overview -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2" style="text-align: center;">
                <h3 style="text-align: center;margin-top: 30px;margin-bottom: 30px;">
                    Overview of iGCT
                </h3>
                <img src="img/overview.png" class="img-responsive center-image" alt="overview" style="width: 70%; text-align: center; margin: 0 auto;">
                <p class="text-justify" style="padding-top: 10px;">
                    iGCT is a DM-independent, data-driven approach that incorporates guidance into CMs. As oppose to training a denoiser that maps noise to image, iGCT's noiser learns to map image to noise by swapping the model's input at training, i.e., the noisier sample becomes the target. The predicted noise latent and denoised image distribution is aligned using the reconstruction loss. Refer to the paper for details.
                </p>
            </div>
        </div>

        <!-- Guidance without Oversaturation -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2" style="text-align: center;">
                <h3 style="padding-bottom: 20px; text-align: center;">
                    Results
                </h3>
                <video autoplay muted loop playsinline width="100%">
                    <!-- t=0.001 is a hack to make iPhone show video thumbnail -->
                   <source src="img/guidance.mp4#t=0.001" type="video/mp4">
                </video>
                <div style="display: flex; justify-content: space-between; padding-bottom: 20px;">
                    <img src="img/results_precision_recall.png" class="img-responsive" alt="Another Image" style="width: 48%; height: auto; object-fit: contain;">
                    <img src="img/results_fid_vs_w.png" class="img-responsive" alt="Another Image" style="width: 48%; height: auto; object-fit: contain;">
                </div>
                <p class="text-justify">
                    iGCT's ability to trade off diversity for precision as guidance strength increases, in contrast to CFG that experiences declines in both quality and diversity beyond a certain threshold.                     <strong>Video: </strong> As guidance strength increases, iGCT trades off diversity for precision without oversaturating the image. Top: EDM 18-steps guided generation. Bottom: iGCT 1-step guided generation.
                </p>
            </div>
        </div>
        
        <!-- Citation -->
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Citation
            </h3>
            <div class="form-group col-md-10 col-md-offset-1">
                <!-- 
                <textarea id="bibtex" class="form-control" readonly="" style="display: none;">    
                </textarea>
                <div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 4px; left: 4px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;" tabindex="0"></textarea></div><div class="CodeMirror-vscrollbar" cm-not-content="true" style="bottom: 0px; min-width: 18px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" cm-not-content="true" style="min-height: 18px;"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 30px; min-height: 539px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span>​</span>x</span></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 4px; top: 0px; height: 17.1406px;">&nbsp;</div></div><div class="CodeMirror-code" style=""><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">@inproceedings{</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">humayun2023splinecam,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">author={Humayun, Ahmed Imtiaz and Balestriero, Randall and Balakrishnan, Guha and Baraniuk, Richard G.},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">title={SplineCam: Exact Visualization and Characterization of Deep Network Geometry and Decision Boundaries},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">month={June},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">year={2023},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">pages={3789-3798}</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">@inproceedings{</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">humayun2022exact,</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">title={Exact Visualization of Deep Neural Network Geometry and Decision Boundary},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">author={Ahmed Imtiaz Humayun and Randall Balestriero and Richard Baraniuk},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">booktitle={NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">year={2022},</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;">}</span></pre><pre class=" CodeMirror-line "><span style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  </span></pre></div></div></div></div></div><div style="position: absolute; height: 30px; width: 1px; top: 539px;"></div><div class="CodeMirror-gutters" style="display: none; height: 569px;"></div></div></div> 
                -->
            </div>
        </div>


    </div>
</body>
</html>
